Create virtual environment
pip install "routellm[serve,eval]"
export OPENAI_API_KEY = Your_openai_API_Key
export GROQ_API_KEY = Your_groq_API_Key
Calibration:  python -m routellm.calibrate_threshold --routers mf --strong-model-pct 0.5
pip install chainlit rich
Add the 'litellm.drop_params=True' in env\Lib\site-packages\litellm\utils.py 
Run the server for UI:  python -m routellm.openai_server --routers mf --weak-model groq/llama3-8b-8192
Run the command:  chainlit run UI.py
